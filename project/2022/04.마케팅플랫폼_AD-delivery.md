## AD delivery

### 일정

- 기간 : 22.04.11 ~ 22.06.24
- Sanity QA: 22.06.27 ~ 22.07.01
- 투입 인력 : 1인

<hr>

### 개발

- ad-delivery 컴포넌트 아키텍쳐 설계.
- 마케팅 상품 및 점포 정보를 ad-delivery로 동기화하는 로직 개발.
- 마케팅 상품을 노출하는 API 개발.

### 컴포넌트 소개

ad-delivery 컴포넌트는 마케팅 플랫폼으로부터 광고 컨텐츠를 동기화하여, 라인페이의 앱/웹에 컨텐츠를 노출시켜주는 컴포넌트입니다. 유저로부터 떨어진 거리가 가까운 순으로 광고를 노출하거나, 랜덤성을 가지고 유저들에게 노출합니다.


### DB 선택은 신중하게

컴포넌트 설계에 있어, DB를 선택하는 것은 매우 중요한 순간 중 하나입니다. ad-delivery 컴포넌트는 주로 geo location query를 사용하기 때문에, 해당 기능을 지원하는 데이터베이스 중에서 선택해야 합니다. 마침 공식문서에서 MySQL 8.0.19부터 geo query가 개선되었다는 내용을 보고, MySQL과 MongoDB의 성능테스트를 통해 적합한 데이터베이스를 선택하기로 했습니다. 테스트 API는 가장 많이 사용되는 기능으로 선택했습니다.

<br>

- 테스트 API: 유저로부터 반경 x km 내의 점포들 중 가장 가까운 순으로 정렬하여 노출.

```sql
SELECT *, ST_Distance_Sphere(ST_GeomFromText('POINT(0 0)', 4326), location) as sdistance
from geo_test
where MBRContains(ST_LineStringFromText('LINESTRING(-0.045 -0.045, 0.045 0.045)', 4326), location)
order by sdistance ASC
limit 100;
```

```mongodb
db.geo_test.aggregate([{$geoNear: {spherical:true, limit:100, maxDistance: 5000, near: {type:"Point", coordinates:[0,0]}, distanceField:'distance', key:'location'}}])
```

<br>

유저의 위치로부터 떨어진 반경을 5km, 50km, 100km로 늘려가며 테스트를 진행했으며, 점포의 수는 50만 건, 500만 건으로 변화시켜가며 테스트를 진행했습니다. 테스트셋은 1000km 사이즈의 정사각형 안에 테스트 데이터를 삽입해, uniform distribution을 가정하였습니다. 적은 데이터와 작은 반경에 대해서는 mongodb와 mysql의 performance가 크게 차이나지 않았지만, (50만, 100km) 테스트 컨디션에 대해서는 1ms : 500ms 정도로 퍼포먼스 차이가 두드러지는 것을 확인할 수 있었습니다. 마찬가지로, (500만, 5km) 테스트 컨디션에 대해서도 1ms : 1s로 성능 차이가 꽤 심각한 걸 확인할 수 있습니다.

물론, mysql에서 지원하는 spatial query에는 거리 순으로 정렬하는 기능이 없기 때문에 order by에서 꽤 많은 시간이 소요됩니다. 하지만 정렬 조건이 없다고 가정하더라도 퍼포먼스의 차이는 크게 줄어들지 않습니다.


#### 결론

MySQL은 geo location query를 사용하려면 데이터의 개수가 적은 상황에 적합합니다. 또한, Index의 구조상 거리 순으로 정렬하기에 적합하지 않으므로, 특정 Polygon에 데이터가 포함되는지 검사하는 경우에 더 유용합니다. MySQL은 PostgreSQL과 동일한 PostGIS 인터페이스를 사용하고 있고, geo query를 위해서라면 postGreSQL을 선택하는 것이 더 나은 선택지일 수 있습니다.

MongoDB의 2dsphere 인덱스는 Haversine fomular를 적용하기 위한 별도의 명령이 필요치 않고, 데이터를 거리순으로 정렬할 수 있다는 장점이 있습니다. 만약 NoSQL을 선택할 수 있는 환경이라면 MongoDB는 geo query를 사용함에 있어 좋은 선택지가 될 수 있어 보입니다.

### 데이터 동기화 설계

ad-delivery는 점포 정보와 광고 컨텐츠를 동기화가 필요한 컴포넌트입니다. 이러한 동기화에 사용할 수 있는 방법으로는 kafka, batch 등의 방법이 사용될 수 있습니다.
점포 정보 동기화에는 kafka를 사용하는 곳이 있어, ad-delivery도 kafka를 통해 동기화를 진행했습니다. 하지만, kafka producing을 하는 주체가 다른 팀에 존재하고, 해당 팀에서 spec 변경으로 인해 kafka message 또한 함께 변경되는 이슈가 종종 나타났습니다. 따라서 ad-delivery에서는 그러한 이슈를 줄이기 위해 kafka message는 change event로만 간주하고, 실제 동기화는 API를 호출하여 진행했습니다.

광고 컨텐츠의 동기화는 kafka를 사용하지 않고 batch system을 이용해 동기화를 진행했습니다. batch system을 이용한 동기화는 추후에 장애가 발생하거나 했을 때, 운영 리소스가 거의 없다는 점에서 채택했습니다.

### Servlet vs Webflux

ad-delivery는 많은 유저에게 광고 데이터를 노출해야 하기 때문에 퍼포먼스가 중요합니다. 게다가 노출 조건을 비교하여 광고를 응답하는 것이 주요 동작이기 때문에 상대적으로 비즈니스 로직이 가볍습니다. 이러한 상황에는 Webflux는 좋은 선택지가 될 수 있습니다. 따라서 Webflux 방식으로 API를 구현하기로 결정했습니다. 개발이 완료된 시점에서 이 둘의 퍼포먼스를 비교해보면 더욱 좋겠지만, Servlet 기반으로 새로운 프로젝트를 만들 여유가 없어 아쉬울 따름입니다.

### 성능 테스트

현재 peak TPS 30. 서비스 런칭 후 예상 peak TPS 150. 목표 TPS 500.


### 회고

같이 개발하기로 했던 시니어 분이 다른 프로젝트에 참여하게 돼서 또 혼자 작업을 하게 됐습니다. 이런 상황에 한 번도 사용해본 적 없는 webflux로 신규 프로젝트를 만들기란 쉽지 않았습니다. (Spring5로 넘어오면서 너무 대격변한게 아닌가..?) 쉽게 설정하던 log filter나 Mdc설정 같은 것도 webflux에서는 하나 하나가 순탄치 않았습니다. Servlet 기반이라면 하루면 개발할 API도 이틀, 삼일씩 걸리며 스트레스를 많이 받았습니다. 지금도 Webflux를 잘 이해하냐고 묻는다면 그건 아니지만, 꽤 적응은 했다고 할 수 있을 것 같습니다.

의지할 팀원이 없는 게 서운할 때도 많지만, 이젠 나름 적응돼서 혼자 일하는 것도 편한 것 같습니다. (인정받는 것 같은 느낌도 많이 들고..) 운영 리소스를 감안한 동기화 설계는 개인적으로도 만족스러운 설계였습니다. 실제 서비스는 8월 이후니 아직은 알 수 없지만, 팀 내에서도 꽤 긍정적인 반응이라 기대가 됩니다.

Sanity test 진행에 꽤 많은 어려움을 겪었습니다. core 컴포넌트가 아니라, 미들 컴포넌트에 위치하다보니 테스트를 하려면 맨 앞단부터 테스트를 시작해야 했습니다. 우리 컴포넌트 버그는 아닌데, 다른 컴포넌트 이슈로 인해 똑같은 테스트를 여러 번 반복하는게 너무 힘들었습니다. 게다가 다른 컴포넌트의 주체가 외주 개발사와 대만 개발자다보니 커뮤니케이션에서 꽤 애를 먹었습니다. Sanity test로 3일을 잡았는데, 부하 직원과 함께 했는데도 5일이 넘게 걸렸습니다. 다음에는 이런 점을 감안해서 리소스를 산정해야할 것 같단 생각이 들었습니다. (MSA에서 미들 컴포넌트의 테스트는 꽤나 괴롭답니다..)