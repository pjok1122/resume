## 대만 App Pos 출시! - Line Pay Good Partner

### 기획

- 앱으로 가맹점의 거래 내역, 정산 내역 등을 조회할 수 있고, 결제 취소, 집계, 동향 등을 파악할 수 있는 관리 목적의 앱이다.

### 일정

- 개발 기간 : 21.03.21 ~ 21.06.10
- 투입 인력 : 3인
- Release : 2021.08.20 배포
- Service on: 2022.01.12 앱 출시

### 개발

개발은 크게 `인증`, `거래/정산 관리`, `점포/스태프 관리` 정도로 나뉘며, 하나의 파트를 맡아서 진행하게 됐다. 이 중에서 내가 맡은 부분은 `거래/정산 관리` 기능이다. 
거래내역 조회, 기간 별 통계, 거래 취소, 정산 내역 조회 등 거래와 정산 내역 관련 모든 기능을 구현한다.

<hr>

### 회고

#### 의사소통은 신중하게

앞서 진행했던 과제들은 주로 기획, UI/UX, Web Dev팀과 주로 소통했다면, **이번 개발 과제는 참여 개발 팀만 Dev4, Web Dev, AOS, IOS, NTS이므로 무엇보다 소통이 중요하다고 생각했다.** 예를 들어 API를 설계했을 때 AOS팀에서는 가능하다고 하지만, IOS팀에서는 불가능하다고 할 수도 있고 Web 팀과 App 팀 사이에 데이터를 주고받을 때 이슈가 있을 수도 있기 때문이다. 따라서 일방적으로 API Spec을 통보하기보단, 이렇게 설계되었을 때 문제가 없을 지 각 개발 팀에 문의를 하고 Sync를 맞추면서 진행했다. 똑같은 이유로 기획에 스펙 변경을 요구할 때에도 각 개발 팀이 인지할 수 있도록 멘션을 잊지않고 진행했다. 사소한 것까지 Sync를 맞추는 게 오버헤드일 수는 있지만, 기획과 개발팀 두 팀만 소통할 때에도 기획에 대한 오해로 구현이 상이한 경우가 제법 많은 걸 봐선 지속적으로 Sync를 맞추는게 현명한 방법이라고 생각한다. 그 증거로, **해당 기능은 4월에 개발 완료된 후로 사소한 변경 외에는 코드의 수정이 전혀 이루어지지 않았다. 다른 기능에 비해 비교적 변화가 적기 때문이기도 하겠지만, 처음부터 어느 팀에서도 문제되지 않도록 Sync가 맞춰져있었기 때문에 가능했던 일이라고 확신한다.**

<br>

#### 성능 개선은 중요해

App Pos는 일본에 서비스를 하고 있고, 일본 앱에서 이미 `거래 내역 조회` API가 동작하고 있다. 따라서 대만 앱에서도 비슷하게 사용할 수 있을거라 생각했지만, 기획이 완전히 상이하여 완전히 새로운 API를 만들어야만 했다. 30일동안 발생한 거래내역을 Filtering해서 거래가 발생한 날짜만 보여주는 기능이 필요한데, Pos에 저장되는 거래내역이 하루에 80만 건으로 30일치를 한 번에 조회할 경우 성능이 안나오는 문제가 있다. 일자별로 거래내역을 보여줘야 하기 때문에 일자별로 거래를 묶어야하고 group by와 같은 작업을 수행하면 Slow API(`3s 이상`)가 되는 문제가 있다. 게다가 DB에는 JST 타임으로 저장되는 반면, 일자별로 조회하기 위해서는 TW timezone으로 변경해야 한다. 이렇게 되면 column에 대한 operation이 들어가기 때문에 DB가 인덱스를 타지 못 하거나 그루핑이 어려운 문제점이 있다.

이 부분을 개선하기 위해 약 3일 정도 쿼리를 여러 방면으로 튜닝하고, DBA에도 도움을 청했으나 별다른 개선점이 나오진 않았다. 구현이 불가능하다고 기획 팀에 요청해서 기획을 수정할 수도 있겠지만, 가능하면 기획이 요구한 스펙대로 구현하고 싶었다. **따라서 시간이 좀 오래 걸리더라도 Aggregation table을 만들기로 결정했다.** 하루에 한 번 daily aggregation을 진행하는 job을 만들었고, daily aggregation 테이블을 이용해 조회하는 경우 API의 응답까지 `10ms` 정도 소요되는 짜릿함을 맛볼 수 있었다.

하지만 daily aggregation을 사용했을 때의 문제점도 존재한다. 자정에 배치가 바로 돌아간다고 해도, 자정에 바로 조회 시에는 daily aggregation에 집계되지 않은 날짜가 반드시 포함될 수 있다. 이 문제를 해결하기 위해 Service layer에서 daily aggregation으로 조회되지 않은 날짜들은 하루씩 개별 조회하도록 API를 개선했다. 코드 자체는 조금 복잡해졌으나, 부득이하게 배치가 돌지 않았다고 하더라도 퍼포먼스와 정합성 모두 잡을 수 있었다. 추후에 추가기획으로 6개월 거래 내역에 대한 리포트 요청이 들어왔는데, 이때는 daily aggregation이 존재하므로 monthly aggregation을 생성해 해결할 수 있었다. 이때도 monthly에 없으면 daily, daily에 없으면 10분 집계에서 조회해오도록 코드를 작성하여 정합성을 잃지 않도록 노력했다.

여태까지 해왔던 과제 중에 가장 도전적인 행동이었고 그 결과, 개발자로서도 서비스 성능 측면에서도 아주 만족스러운 결과를 얻은 것 같다. 

<br>

#### 데이터 마이그레이션

Line Pay Good Partner 앱에서는 거래내역 조회 시에 결제가 발생한 플랫폼 별로 필터링할 수 있는 기능이 있다. LINEPAY 내부 결제인지, wechat Pay결제인지, naver pay 결제인지, LINEPAY 해외 결제인지 등으로 필터링을 할 수 있다. 하지만 기존의 posdb에는 결제 플랫폼에 대한 정보를 저장하지 않고 있었다. 따라서 이를 해결하기 위해 Central로부터 데이터를 마이그레이션해야만 하는 상황이 발생했다.

나는 central-batch -> pos-consumer로 API를 만들어두고, batch에서 읽어들여 pos-consumer API를 호출하는 방식으로 마이그레이션을 진행했다. kafka를 이용한 동기화도 가능하지만 kafka를 이용하면 다른 컴포넌트에서도 consume이 발생하게 된다. 이때 다른 컴포넌트에서 idempotent한 동작으로 처리되고 있는지도 알 수 없고 로그가 무분별하게 쌓일 수 있기 때문에 다른 컴포넌트에 영향도가 없도록 API로 진행했다. RC 환경에서 API의 처리속도와 API 호출하는 쪽의 thread 수를 모니터링하면서 성능에 이슈가 없도록 설정했고, 약 2달 간의 꾸준한 마이그레이션을 통해 마이그레이션 작업을 끝낼 수 있었다. 즉, 2달 간 매일 아침 batch를 돌리고, disk나 cpu 등에 이슈가 없었는지 체크를 해야했으니 굉장히 tidious한 작업이었다.

MSA 설계의 장점은 정말 많지만, DB에 필요한 필드를 추가하는 과정이 생길 때마다 마이그레이션과 같은 작업을 수행해야 하고, 또는 누락 건이 있을 때 챙겨줘야 하는 운영상의 코스트가 있는 것 같다. 실제로 이 마이그레이션을 수행하는 동안 기존 스펙의 버그가 발견되어, 마이그레이션을 새로 돌려야 하는 상황이 발생했다. 그렇다고 **쓰지도 않는 필드를 모두 다 저장하면 MSA의 장점을 살리지 못하는 꼴이고 필요한 필드만 저장하자니 기획이 변경될 때마다 마이그레이션을 수행해야 하니, 프로젝트의 방향성을 보고 필요한 데이터를 잘 선정해두는 것도 하나의 키포인트가 될 수 있을 것 같다.** 물론 사업의 방향성을 개발 쪽에서 알기는 쉽지 않겠지만 말이다. 이런 고민들은 명확한 정답은 없지만 본인의 경험과 회사의 특성을 종합해서 어느정도 노하우로 터득되지 않을까 싶다.

#### 정산은 어려워

거래 내역은 그나마 일본 App Pos API를 참고해서 취소나 결제의 flow를 어느정도 파악할 수는 있었다. 하지만 정산은 우리 팀 컴포넌트 어디에도 존재하지 않았고, API Spec을 봐도 이해하기가 너무 어려웠다. 팀원 분들도 정산 쪽에 대해서는 무지한 상태였기에 혼자 이 난관을 헤쳐나가야만 했다. 그나마 다행인 점은 기획에 나와있는 기능들이 Merchant Center(NTS)에서 이미 사용 중인 기능들이라는 점이다. 그래서 NTS, Dev2, 기획팀의 지원을 받아서 해결을 하려 했으나 이마저도 쉽지 않았다. Dev2에서는 기획에 나와있는 값들이 어떤 의미를 갖는지 모르고 이해하지 못하는 상황이셨고, 기획에서도 내부적인 로직이 어떻게 되는지에 대해서는 전혀 모른다고 하셨다. NTS는 오래전에 개발된 소스 코드이고, 수정이 없었기에 논리적으로 설명이 불가능했다. 

**이 문제점을 해결하기 위해 Merchant Center의 settle쪽 소스코드를 전부 뜯어보고 동일한 동작을 하도록 우리 서비스에 맞춰서 리팩토링해서 구현했다.** 코드에서 유추했을 때 `이월금액을 빼는 구나`와 같은 동작들을 유추할 수는 있지만, 정산에 대한 로직을 모르기 때문에 이게 맞는 로직인지 확인하는 게 어려웠다. 따라서 기획과 QA에는 최대한 꼼꼼하게 테스트해주길 요청드렸고, 나 또한 각종 테스트 시나리오를 만들어서 Center와 동일한 결과가 나오는지 수차례 검증했다. 주어진 상황에 맞춰, Center 쪽 코드에 맞춰서 개발을 진행하고 수 많은 테스트로 검증을 수행했지만 이 방법이 옳다고 생각하진 않는다. 하지만 다음에 또 이런 상황이 오게되면 어떻게 해야할 지 잘 모르겠다. PIC에게 요청해서 Dev2, 기획, Dev4, NTS 회의를 잡고 어떻게 코드를 짜야하는지 물어보는게 맞는 걸까?


 저는 모든 프로젝트에서 항상 여러 가지 가능성에 대해서 생각해보고 최선의 방법과 최적의 방법을 찾기 위해 노력하는 편입니다. 가장 괜찮아 보이는 방법을 선택하면 팀 내에 공유하고 모든 팀원들의 동의를 받고 있습니다. 이 외에도 저는 유지보수성이 좋은 코드를 짜기 위해 부던히 노력합니다. Line pay의 특성상 한 명의 개발자가 2~3개의 컴포넌트를 동시에 맡아서 진행하는 경우가 많기 때문에 운영 리소스에 투입되는 시간이 매우 많습니다. 따라서 운영 리소스를 줄이고 개발과 설계에 리소스를 투입하기 위해 유지보수성이 높은 코드를 작성하고자 노력하고 있습니다. 주로 개발 시점에 '재처리'가 필요할 것 같은 곳에는 로그를 적절히 심어 놓고, '멱등성'을 보장하는 방식으로 설계 하고 있습니다.

 대만에서 라인페이 가맹점주들 대상으로 거래, 정산 기능을 관리할 수 있는 pos 앱을 출시 했습니다. 저희 팀에서는 총 세 개의 파트로 나누어 개발을 진행하였고, 앱의 핵심 기능인 거래/정산 관리 기능 개발을 진행하였습니다. 제가 거래/정산 관리 기능을 맡게 된 이유는 일본에서 서비스 중인 앱과 대만에서 출시하려는 앱의 기능이 유사한 점이 많았고 해당 소스 코드를 참고할 수 있을 것 같다고 판단 되었기 때문입니다. 하지만 기획서를 분석한 결과, 일본 서비스의 코드를 사용할 수 있는 기능은 거의 없었습니다. 특히, 일본 서비스에 구현되어있는 거래 내역 조회 기능을 대만에서 그대로 사용하기에는 여러가지 문제가 있었습니다. 
 첫 번째 이슈는 timezone 이슈입니다. 일본 서비스에 구현되어있는 API는 날짜 별로 결제액, 환불액 등을 요약해서 노출하고 있습니다. 날짜 별로 노출하기 위해 GROUP BY 조건을 사용하고 있고, YYYYMMDDHHmmss와 같은 simple date time에서 8자리를 끊어, YYYYMMDD가 같으면 같은 날짜로 처리해 노출하고 있습니다. 이것이 가능한 이유는 mySQL에 저장되는 날짜 포맷의 데이터는 일본의 Local timezone인 GMT+9의 타입으로 저장하는 것이 회사의 컨벤션이기 때문입니다. 하지만 일본과 대만은 시차가 1시간이 존재합니다. 따라서 위와 같은 방식으로 YYYYMMDD를 group으로 묶을 경우, 제대로 된 결과를 제공할 수 없습니다.
 이 이슈를 해결 하기 위해, query tuning을 해봤지만 날짜 형식에 operation을 가하는 경우 Index를 제대로 탈 수 없기 때문에 DBA와 의논한 결과 이 방법으로는 좋은 퍼포먼스를 내기는 힘들 것이라 판단했습니다. DB에서 해당하는 기간동안의 데이터를 전부 조회한 후 application에서 묶는 방법도 있을 수 있지만, 하루의 거래 데이터가 '80만개'이고 세븐일레븐처럼 규모가 큰 가맹점의 경우 데이터가 상당히 많기 때문에 한달 치의 데이터를 application에 로드하는 것은 불가능합니다. 다음 방법으로는 '30일'의 기간 중 거래가 있는 날짜만 묶어서 조회하는 행동을 '하루'에 대한 조회를 '30번' 발생시키는 방식으로 해결할 수 있지 않을까 생각했습니다. 물론 이 방법을 Synchronous하게 수행할 경우 퍼포먼스가 나올리 만무하기 때문에 Asynchronous한 방법으로 수행할 생각이었습니다. 하지만 이 방법은 risk가 매우 큰 방법이기 때문에 보류했습니다. 마지막 방법은 '일간 집계 테이블'을 생성하는 것이었습니다. 이 방법은 추가적인 개발이 필요하므로 리소스가 많이 들지만 퍼포먼스가 가장 잘 나오는 방법이라고 생각하여 선택하게 되었습니다. 이 방법은 간단합니다. 하루가 넘어가는 날, 이전 날에 발생했던 거래내역들을 가맹점 별로 집계하여 테이블에 쌓아두는 것입니다. 이때 국가별 시차를 고려하여 daily 집계를 하기 때문에, timezone으로 인해 쿼리가 복잡해지는 이슈가 해결됩니다. 이 집계를 만들고 최근 2년치 데이터를 집계해두기만 하면 30일 간 거래가 있는 날짜를 조회하는 것은 1ms 내로 처리할 수 있습니다. 이런 batch job은 거래내역의 누락이 발생했거나 하는 경우, 잘못된 집계가 될 수가 있으므로 배치를 다시 돌렸을 때 멱등성을 보장하도록 설계하여, 추후에 운영리소스가 투입되는 것을 조금이나마 줄이려고 하였습니다. 하지만 '일간 집계 테이블'을 이용한 방식에도 새로운 이슈가 존재합니다.
 배치가 돌아가는 시간 동안에는 집계가 되어있지 않은 상태이기 때문에 유저에게 집계 결과가 잘못노출될 수 있다는 점입니다. 하루 데이터를 집계하는 데에 대략 30분정도 소요되기 때문에 유저는 0시부터 0시 30분 간 '어제'의 결과를 제대로 받아볼 수 없게 됩니다. 사실 이 문제는 배치가 없더라도 '오늘' 날짜에 대한 집계가 되어있지 않기 때문에, 오늘 날짜에 대한 조회는 제대로 동작하지 않습니다. 따라서 이 두 문제를 한 번에 해결하는 방법을 떠올렸습니다. 그 방법은 '일간 집계 테이블'에 집계된 가장 마지막 날짜를 참고하는 것입니다. 가령, 7월 1일부터 7월 30일까지의 데이터를 조회한다고 했을 때, 집계 테이블에 7월27일까지의 데이터가 존재한다면, 7월 27일까지의 데이터는 집계 테이블에서 조회하고, 7월 28일부터 7월 30일까지의 데이터는 '10분 단위 집계' 테이블을 이용해 조회합니다. 그리고 유저에게 제공할 때는 이 두 결과를 merge하여 제공하도록 처리하였습니다.
 이러한 방법을 선택한 이유는 여러 가지가 있지만 첫 번째는 가독성입니다. 위의 상황을 문자 그대로 표현하면, '오늘날짜 이거나, 0시부터 약 0시 30분 사이에 있는 경우 어제 날짜에 대한 집계가 되지 않았을 수 있다.' 입니다. 이는 굉장히 이해하기 어려운 문장이며, 배치의 퍼포먼스에 따라 걸리는 시간이 달라질 수 있기 때문에 처리하기가 매우 까다로워집니다. 반면에, '데일리 집계 테이블에 존재하는 데이터까지만 조회하고, 존재하지 않으면 10분 단위 집계에서 조회'. 라는 문장은 위의 두 가지 상황을 모두 처리할 수 있는 아주 가독성 좋은 문장입니다. 
 두 번째 이유는 데이터의 정합성입니다. 만약, 위와 같이 구성하지 않고 7월 1일부터 7월 30일까지의 데이터 중 '오늘'과 '어제'를 포함하고 있으면, '오늘'과 '어제'는 10분단위 테이블에서 집계한다고 가정해 봅시다. 그럴 경우, 배치에 이슈가 생겨 동작하지 않는 상태로 며칠이 지났을 때 이는 장애로 이어지게 됩니다. 하지만, 제가 선택한 방법은 배치에 이슈가 생겨 동작하지 않았다고 하더라도, 유저에게 노출되는 데이터는 정상적으로 노출될 수 있습니다. 
 이렇게 merge를 이용한 방법은 '10분 단위' 집계에서 데이터 조회가 발생하면 최대 10ms까지 소요되지만, 집계가 되어있는 데이터만을 조회하는 경우에는 1ms로 응답이 처리될 수 있습니다. 일본 서비스에서 사용하던 쿼리를 사용할 경우 10초 가량 걸리는 문제점을 이와 같은 해결 방법을 통해 10ms까지 줄일 수 있었습니다. 또한, 이 작업 자체는 일본 서비스에서도 사용할 수 있게 구성하였으며, 일본 API에서도 2초가 걸리던 API를 10ms로 줄일 수 있었습니다.

 집계 테이블과 집계가 되지 않은 데이터가 존재하는 경우 '10분 단위 집계' 테이블에서 조회하도록 하는 방법은 거래내역 report API에서도 그대로 사용했습니다. 이 report API는 6개월 간의 집계 데이터를 노출하는 것으로, 성능 튜닝을 하기 위해서는 월간 집계가 필요합니다. 매달 1일 0시마다 '일간 집계 테이블'을 집계하여 '월간 집계 테이블'을 만들었습니다. 이 report API 또한 이번달을 포함하거나, 0시에 조회하는 경우, 아직 집계되지 않았을 수 있어 제대로된 결과를 얻지 못할 수 있습니다. 따라서 위의 방법과 마찬가지로 1월부터 7월까지의 월간 집계 report를 조회한다면, '월간 집계 테이블'에 존재하는 데이터까지 조회. 존재하지 않는 데이터는 '일간 집계 테이블'에서 조회. '일간 집계 테이블'에 없는 데이터는 '10분 단위 집계 테이블'에서 조회하여 이 데이터를 merging 하는 방식으로 구현했습니다.

 두 번째 이슈는 구현에 필요한 데이터가 데이터베이스에 존재하지 않는다는 점입니다. pos 서비스는 MSA로 구성되어있고 central로부터 kafka를 통해 거래내역 데이터를 받아와 필요한 데이터만 저장하고 있습니다. 하지만, 기획에서 원하는 요구사항을 구현하기 위해서는 추가적인 필드가 필요한 상황이었습니다. 따라서 기획팀과 논의를 통해 해당 기능이 반드시 필요한 기능인지 확인을 받았고, 데이터 마이그레이션이 필요하다고 팀 내에 공유하였습니다. 마이그레이션의 방법으로는 가장 먼저 kafka를 이용한 방식을 떠올렸지만, 이는 굉장히 위험한 방법이라고 생각했습니다. 마이그레이션을 위해 날짜가 지난 '거래 내역' 정보를 큐에 넣었을 때, 이를 컨슘하는 모든 컴포넌트의 동작을 알 수가 없기 때문입니다. 만약 멱등성을 보장하지 않는 서비스가 존재한다면, 이는 장애로 이어질 수 있습니다. 뿐만 아니라, queue에 이전 거래내역으로 가득 차게 되어 최근에 발생한 거래 내역 정보가 늦게 처리되는 이슈가 발생할 수 있습니다. 예를 들면 혜택을 늦게 제공한다거나, 결제 내역 push 알람이 늦게 온다거나 할 수 있습니다.
 따라서 다른 컴포넌트에 영향을 주지 않도록 API를 이용한 마이그레이션을 하기로 결정했습니다. central-batch에서 거래내역 DTO를 생성하고, 이를 pos-consumer 쪽 신규 API를 호출하도록 결정했습니다. 여기서 pos-consumer를 사용한 이유는, pos-api 컴포넌트에 생성할 경우 마이그레이션의 부하로 인해 유저에게 영향을 끼칠 수도 있다고 판단했기 때문입니다. 따라서 상대적으로 부하가 적은 pos-consumer에 신규 API를 만들어 처리했습니다. 이 마이그레이션 작업에서 가장 중요하게 생각한 것은 데이터가 누락되지 않는 것이었습니다. 데이터의 누락이 발생한 경우, 이를 재보정해야 하기 때문에 추가적인 리소스 투입이 필요하기 때문입니다. 따라서 pos-consumer에서 안정적인 처리를 할 수 있도록 배압조절에 신경을 썼습니다. pos-consumer는 List<TransactionDTO>를 받아서 처리하기 때문에 List의 사이즈가 중요합니다. 따라서 central-bacth에서 spring batch의 chunk size를 50으로 지정하였고, page size는 1000개로 제한했습니다. 따라서 1 page 마다 총 20개의 묶음이 만들어질 수 있고, pos-consumer에서 최대 20개의 thread까지만 활성화되도록 하는 것이 목표였습니다. Line pay의 모니터링 툴을 이용해 활성화된 thread 수를 모니터링 한 결과, thread 수가 증가하지 않는 걸 확인했습니다. 이는 consumer의 처리 속도가 producer의 속도보다 늦지 않다는 것을 의미하기 때문에 해당 수치로 마이그레이션을 진행했습니다. 초기에는 하루씩 데이터를 마이그레이션하며 동향을 지켜보았고, 점차 하루씩 늘려나가 10일씩 집계하였습니다. 총 2년치의 데이터로, 약 6억개 가량의 데이터를 동기화해야 하기 때문에 반복적인 작업이 필요했고, 이를 놓치지않기 위해 calendar에 작업을 추가해 약 두 달간 매일 10분씩 모니터링 및 batch trigger를 하였습니다.

출시 일이 정해져있는 상황에서 신규 테이블을 추가하고 마이그레이션을 하는 행동은 굉장히 도전적인 행동이었지만, 그 결과 자체는 매우 성공적이었던 것 같습니다. 마이그레이션 도중에 이슈가 발생하거나, 테이블 집계에 문제가 있을 경우 서비스 출시일이 미뤄져야할 수 도 있는 상황이었지만 테스트코드 작성과 꼼꼼한 유저 사용성 측면에서 충분히 고민하여 높은 퍼포먼스를 낼 수 있었던 것 같고, 유지보수 측면에 대해서도 굉장히 만족스러운 결과를 얻었습니다. 해당 코드 작업이 수행된지 1년 이상이 지났고, 서비스를 출시한 지도 6개월 이상 지난 지금까지도 해당 기능에 대한 수정이나 버그 대응할 것이 없었습니다. 최대 30일로 제한되어있던 거래 내역 기간은 가맹점주들의 요구사항에 의해 365일로 늘어났음에도 성능적인 문제가 발생하지 않고 있고, 코드 대응할 것도 없었습니다. 만약 이런 개선 작업을 하지 않고, 보일러 플레이트 코드를 작성하였다면 365일로 기간을 연장하는 것은 굉장히 큰 소스 작업이 필요하거나 기획을 거부해야 하는 상황이 나왔을 것입니다.